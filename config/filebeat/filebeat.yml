filebeat.inputs:
  - type: docker
    combine_partial: true
    containers:
      path: "/usr/share/dockerlogs/data"
      stream: "stdout"
      ids:
        - "*"
    exclude_files: ['\.gz$']
    ignore_older: 10m

processors:
  # Decodifica o log field (Documento JSON) se for codificado em JSON e mapeie seus campos para o elasticsearch
  - decode_json_fields:
      fields: ["log", "message", "msg"]
      target: ""
      # Sobrescreve os campos existentes no elasticsearch enquanto decodifica os campos json
      overwrite_keys: true
  - add_docker_metadata:
      # Anota cada evento com metadados relevantes de contêineres Docker
      host: "unix:///var/run/docker.sock"
  - drop_fields:
      # Desconsiderando/limpando os campos a baixo
      fields: ["container.labels.io_buildpacks_build_metadata", "container.labels.io_buildpacks_lifecycle_metadata", "container.labels.io_buildpacks_stack_id"]

filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false

# configurar filebeat para enviar saída para logstash
output.logstash:
  hosts: ["logstash"]

# Grave os próprios logs do Filebeat apenas no arquivo para evitar capturá-los com ele mesmo nos arquivos de log do docker
logging.level: info
logging.to_files: false
logging.to_syslog: false
loggins.metrice.enabled: false
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
ssl.verification_mode: none